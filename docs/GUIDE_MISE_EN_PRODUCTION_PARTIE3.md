# üöÄ Guide de Mise en Production - Partie 3 (Finale)

**Suite de**: [GUIDE_MISE_EN_PRODUCTION_PARTIE2.md](GUIDE_MISE_EN_PRODUCTION_PARTIE2.md)

---

## üîß Maintenance

### 9.1 T√¢ches Quotidiennes

```bash
#!/bin/bash
# Script: daily_maintenance.sh
# Crontab: 0 6 * * * /usr/local/bin/daily_maintenance.sh

LOG_FILE="/var/log/samaconso/daily_maintenance.log"
DATE=$(date +"%Y-%m-%d %H:%M:%S")

echo "[$DATE] D√©but de la maintenance quotidienne" >> $LOG_FILE

# 1. V√©rifier l'espace disque
echo "V√©rification espace disque..." >> $LOG_FILE
df -h | grep -E "/$|/data" >> $LOG_FILE

DISK_USAGE=$(df -h / | awk 'NR==2 {print $5}' | sed 's/%//')
if [ $DISK_USAGE -gt 85 ]; then
    echo "‚ö†Ô∏è ALERTE: Espace disque > 85%" >> $LOG_FILE
    # Envoyer une alerte
    echo "Espace disque critique sur $(hostname)" | mail -s "Alerte SamaConso" ops@senelec.sn
fi

# 2. V√©rifier les services Docker
echo "V√©rification services Docker..." >> $LOG_FILE
docker ps --format "table {{.Names}}\t{{.Status}}" >> $LOG_FILE

# 3. Nettoyer les images Docker inutilis√©es
echo "Nettoyage images Docker..." >> $LOG_FILE
docker image prune -af --filter "until=72h" >> $LOG_FILE 2>&1

# 4. V√©rifier les logs d'erreur
echo "Analyse logs d'erreur..." >> $LOG_FILE
ERROR_COUNT=$(grep -c "ERROR\|CRITICAL" /opt/samaconso/logs/*.log)
if [ $ERROR_COUNT -gt 100 ]; then
    echo "‚ö†Ô∏è ALERTE: $ERROR_COUNT erreurs d√©tect√©es" >> $LOG_FILE
fi

# 5. V√©rifier la connectivit√© aux bases de donn√©es
echo "Test connectivit√© bases de donn√©es..." >> $LOG_FILE
psql -h 10.101.X.X1 -p 6432 -U samaconso_user -d samaconso -c "SELECT 1;" >> $LOG_FILE 2>&1
if [ $? -eq 0 ]; then
    echo "‚úÖ PostgreSQL OK" >> $LOG_FILE
else
    echo "‚ùå PostgreSQL ERREUR" >> $LOG_FILE
fi

# 6. V√©rifier Redis
redis-cli -h 10.101.X.X3 ping >> $LOG_FILE 2>&1
if [ $? -eq 0 ]; then
    echo "‚úÖ Redis OK" >> $LOG_FILE
else
    echo "‚ùå Redis ERREUR" >> $LOG_FILE
fi

echo "[$DATE] Maintenance quotidienne termin√©e" >> $LOG_FILE
echo "---" >> $LOG_FILE
```

### 9.2 T√¢ches Hebdomadaires

```bash
#!/bin/bash
# Script: weekly_maintenance.sh
# Crontab: 0 3 * * 0 /usr/local/bin/weekly_maintenance.sh

LOG_FILE="/var/log/samaconso/weekly_maintenance.log"
DATE=$(date +"%Y-%m-%d %H:%M:%S")

echo "[$DATE] D√©but de la maintenance hebdomadaire" >> $LOG_FILE

# 1. Analyse des performances PostgreSQL
echo "Analyse performances PostgreSQL..." >> $LOG_FILE
psql -h 10.101.X.X1 -p 6432 -U samaconso_user -d samaconso <<EOF >> $LOG_FILE
-- Tables les plus volumineuses
SELECT schemaname, tablename, pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size
FROM pg_tables
WHERE schemaname = 'public'
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC
LIMIT 10;

-- Index manquants potentiels
SELECT schemaname, tablename, attname, n_distinct, correlation
FROM pg_stats
WHERE schemaname = 'public'
  AND n_distinct > 100
  AND correlation < 0.1
ORDER BY n_distinct DESC
LIMIT 10;

-- Requ√™tes lentes (> 1 seconde)
SELECT query, calls, total_time, mean_time
FROM pg_stat_statements
WHERE mean_time > 1000
ORDER BY mean_time DESC
LIMIT 10;
EOF

# 2. Vacuum et Analyze
echo "Vacuum et Analyze..." >> $LOG_FILE
psql -h 10.101.X.X1 -p 6432 -U samaconso_user -d samaconso -c "VACUUM ANALYZE;" >> $LOG_FILE 2>&1

# 3. Statistiques Redis
echo "Statistiques Redis..." >> $LOG_FILE
redis-cli -h 10.101.X.X3 INFO stats >> $LOG_FILE

# 4. Statistiques RabbitMQ
echo "Statistiques RabbitMQ..." >> $LOG_FILE
curl -s -u guest:guest http://10.101.X.X2:15672/api/overview | python3 -m json.tool >> $LOG_FILE

# 5. Rapport Celery
echo "Rapport Celery..." >> $LOG_FILE
curl -s http://10.101.X.X3:5555/api/workers --user admin:admin | python3 -m json.tool >> $LOG_FILE

# 6. Nettoyer les anciens backups (> 30 jours)
echo "Nettoyage backups anciens..." >> $LOG_FILE
find /data/backups -type f -mtime +30 -delete >> $LOG_FILE 2>&1

# 7. Rotation des logs applicatifs
echo "Rotation logs..." >> $LOG_FILE
find /opt/samaconso/logs -name "*.log" -type f -mtime +7 -exec gzip {} \; >> $LOG_FILE 2>&1

echo "[$DATE] Maintenance hebdomadaire termin√©e" >> $LOG_FILE
echo "---" >> $LOG_FILE
```

### 9.3 T√¢ches Mensuelles

```bash
#!/bin/bash
# Script: monthly_maintenance.sh
# √Ä ex√©cuter manuellement le 1er de chaque mois

echo "üóìÔ∏è Maintenance mensuelle - $(date)"

# 1. Mise √† jour du syst√®me (avec prudence)
echo "V√©rification des mises √† jour syst√®me..."
sudo apt update
sudo apt list --upgradable

# 2. Audit de s√©curit√©
echo "Audit de s√©curit√©..."
sudo apt install -y lynis
sudo lynis audit system

# 3. Revue des utilisateurs et acc√®s
echo "Revue des utilisateurs..."
awk -F: '$3 >= 1000 {print $1}' /etc/passwd

# 4. V√©rification des certificats SSL
echo "V√©rification certificats SSL..."
# V√©rifier expiration certificats

# 5. Test de restauration backup
echo "Test restauration backup..."
# Restaurer le dernier backup sur un serveur de test

# 6. Revue des logs de s√©curit√©
echo "Revue logs s√©curit√©..."
sudo grep -i "failed\|error\|warning" /var/log/auth.log | tail -n 100

# 7. Optimisation base de donn√©es
echo "Optimisation PostgreSQL..."
psql -h 10.101.X.X1 -p 6432 -U postgres -d samaconso -c "REINDEX DATABASE samaconso;"

# 8. Rapport mensuel
echo "G√©n√©ration rapport mensuel..."
# Script pour g√©n√©rer un rapport d√©taill√©
```

### 9.4 Nettoyage et Optimisation

#### PostgreSQL

```sql
-- Script: optimize_postgresql.sql
-- √Ä ex√©cuter mensuellement

-- 1. Vacuum complet
VACUUM FULL ANALYZE;

-- 2. Reindex
REINDEX DATABASE samaconso;

-- 3. Statistiques sur les tables volumineuses
SELECT schemaname, tablename,
       pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS total_size,
       pg_size_pretty(pg_relation_size(schemaname||'.'||tablename)) AS table_size,
       pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename) - pg_relation_size(schemaname||'.'||tablename)) AS index_size
FROM pg_tables
WHERE schemaname = 'public'
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC
LIMIT 20;

-- 4. Identifier les index inutilis√©s
SELECT schemaname, tablename, indexname, idx_scan
FROM pg_stat_user_indexes
WHERE idx_scan = 0
  AND indexrelname NOT LIKE '%_pkey';

-- 5. Analyser les requ√™tes lentes
SELECT query, calls, total_time, mean_time, max_time
FROM pg_stat_statements
WHERE mean_time > 100  -- Requ√™tes > 100ms en moyenne
ORDER BY mean_time DESC
LIMIT 20;
```

#### Redis

```bash
# Nettoyage Redis
redis-cli -h 10.101.X.X3 <<EOF
# Voir la m√©moire utilis√©e
INFO memory

# Supprimer les cl√©s expir√©es
# (Redis le fait automatiquement, mais on peut forcer)
FLUSHDB  # ATTENTION: Supprime toutes les cl√©s de la DB courante
EOF
```

#### Docker

```bash
#!/bin/bash
# Script: docker_cleanup.sh

echo "Nettoyage Docker..."

# Arr√™ter les conteneurs non utilis√©s
docker container prune -f

# Supprimer les images non utilis√©es
docker image prune -af --filter "until=168h"  # 7 jours

# Supprimer les volumes non utilis√©s
docker volume prune -f

# Supprimer les r√©seaux non utilis√©s
docker network prune -f

# Supprimer le build cache
docker builder prune -af

# Afficher l'espace lib√©r√©
docker system df
```

---

## üö® Troubleshooting

### 10.1 Probl√®mes Courants

#### Probl√®me 1: API ne r√©pond pas (502/503)

**Sympt√¥mes**:
- Load Balancer retourne 502 Bad Gateway ou 503 Service Unavailable
- Health checks √©chouent

**Diagnostic**:
```bash
# 1. V√©rifier l'√©tat des conteneurs
docker ps
docker logs samaconso_api_1 --tail 50
docker logs samaconso_api_2 --tail 50

# 2. V√©rifier la connectivit√© r√©seau
curl http://localhost:8001/health
curl http://localhost:8002/health

# 3. V√©rifier les resources
docker stats --no-stream

# 4. V√©rifier les logs syst√®me
journalctl -u docker -n 100
```

**Solutions**:
```bash
# Solution 1: Red√©marrer les conteneurs
docker restart samaconso_api_1 samaconso_api_2

# Solution 2: V√©rifier la base de donn√©es
psql -h 10.101.X.X1 -p 6432 -U samaconso_user -d samaconso -c "SELECT 1;"

# Solution 3: Augmenter les resources (si OOM)
# Modifier docker-compose.production.yml:
#   limits:
#     memory: 4G  # Au lieu de 2G

# Solution 4: V√©rifier le proxy Senelec
curl -x http://10.101.201.204:8080 https://oauth2.googleapis.com

# Solution 5: Rollback si n√©cessaire
./rollback.sh <version_precedente>
```

#### Probl√®me 2: Notifications ne sont pas envoy√©es

**Sympt√¥mes**:
- T√¢ches en statut PENDING dans Flower
- Utilisateurs ne re√ßoivent pas de notifications

**Diagnostic**:
```bash
# 1. V√©rifier les workers Celery
docker logs samaconso_celery_worker_1 --tail 50
docker logs samaconso_celery_worker_2 --tail 50

# 2. V√©rifier les queues dans Flower
curl -s http://10.101.X.X3:5555/api/queues --user admin:admin

# 3. V√©rifier que les workers √©coutent les bonnes queues
docker logs samaconso_celery_worker_1 | grep "queues"
# Doit afficher: urgent, high_priority, normal, low_priority

# 4. V√©rifier RabbitMQ
curl -s -u guest:guest http://10.101.X.X2:15672/api/queues
```

**Solutions**:
```bash
# Solution 1: Red√©marrer les workers
docker restart samaconso_celery_worker_1 samaconso_celery_worker_2

# Solution 2: V√©rifier Firebase
docker exec samaconso_celery_worker_1 python -c "import firebase_admin; print('OK')"

# Solution 3: Purger les queues si trop de messages
rabbitmqctl purge_queue low_priority

# Solution 4: Augmenter le nombre de workers (si charge √©lev√©e)
docker-compose -f docker-compose.workers.yml up -d --scale celery_worker_2=2
```

#### Probl√®me 3: Base de donn√©es lente

**Sympt√¥mes**:
- Requ√™tes API tr√®s lentes (> 5 secondes)
- Timeout des connexions

**Diagnostic**:
```sql
-- 1. Requ√™tes en cours
SELECT pid, age(clock_timestamp(), query_start), usename, query, state
FROM pg_stat_activity
WHERE state != 'idle' AND query NOT ILIKE '%pg_stat_activity%'
ORDER BY query_start DESC;

-- 2. Locks
SELECT blocked_locks.pid AS blocked_pid,
       blocked_activity.usename AS blocked_user,
       blocking_locks.pid AS blocking_pid,
       blocking_activity.usename AS blocking_user,
       blocked_activity.query AS blocked_statement,
       blocking_activity.query AS blocking_statement
FROM pg_catalog.pg_locks blocked_locks
JOIN pg_catalog.pg_stat_activity blocked_activity ON blocked_activity.pid = blocked_locks.pid
JOIN pg_catalog.pg_locks blocking_locks ON blocking_locks.locktype = blocked_locks.locktype
JOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid
WHERE NOT blocked_locks.granted;

-- 3. Statistiques connexions
SELECT count(*), state
FROM pg_stat_activity
GROUP BY state;

-- 4. Cache hit ratio (doit √™tre > 99%)
SELECT
  sum(heap_blks_read) as heap_read,
  sum(heap_blks_hit)  as heap_hit,
  sum(heap_blks_hit) / (sum(heap_blks_hit) + sum(heap_blks_read)) as ratio
FROM pg_statio_user_tables;
```

**Solutions**:
```bash
# Solution 1: Terminer les requ√™tes longues
psql -h 10.101.X.X1 -p 6432 -U postgres -d samaconso <<EOF
SELECT pg_terminate_backend(pid)
FROM pg_stat_activity
WHERE age(clock_timestamp(), query_start) > interval '5 minutes'
  AND state != 'idle';
EOF

# Solution 2: Augmenter les connexions PgBouncer
# Modifier /etc/pgbouncer/pgbouncer.ini:
# default_pool_size = 150  # Au lieu de 100

# Solution 3: Vacuum urgent
psql -h 10.101.X.X1 -p 5432 -U postgres -d samaconso -c "VACUUM ANALYZE;"

# Solution 4: Red√©marrer PostgreSQL (en dernier recours)
sudo systemctl restart postgresql
```

#### Probl√®me 4: Espace disque satur√©

**Sympt√¥mes**:
- Erreur "No space left on device"
- Services crashent

**Diagnostic**:
```bash
# 1. Voir l'utilisation globale
df -h

# 2. Trouver les gros fichiers
du -h / | sort -rh | head -20

# 3. Voir les logs volumineux
du -sh /var/log/* | sort -rh

# 4. Voir les volumes Docker
docker system df -v
```

**Solutions**:
```bash
# Solution 1: Nettoyer les logs
journalctl --vacuum-time=3d
find /var/log -name "*.gz" -type f -mtime +7 -delete
find /opt/samaconso/logs -name "*.log" -type f -mtime +7 -delete

# Solution 2: Nettoyer Docker
docker system prune -af --volumes

# Solution 3: Nettoyer PostgreSQL WAL
psql -h localhost -p 5432 -U postgres -c "CHECKPOINT;"
find /var/lib/postgresql/15/main/pg_wal -type f -mtime +3 -delete

# Solution 4: Nettoyer backups anciens
find /data/backups -type f -mtime +30 -delete

# Solution 5: √âtendre le volume (si possible)
# Contacter l'√©quipe infrastructure
```

#### Probl√®me 5: Redis m√©moire pleine

**Sympt√¥mes**:
- Erreur "OOM command not allowed when used memory > 'maxmemory'"
- Cache inefficace

**Diagnostic**:
```bash
# Statistiques m√©moire
redis-cli -h 10.101.X.X3 INFO memory

# Nombre de cl√©s
redis-cli -h 10.101.X.X3 DBSIZE

# Analyser les cl√©s
redis-cli -h 10.101.X.X3 --bigkeys
```

**Solutions**:
```bash
# Solution 1: Flush manuellement (si urgent)
redis-cli -h 10.101.X.X3 FLUSHDB

# Solution 2: Augmenter maxmemory
# Modifier docker-compose.workers.yml:
# --maxmemory 6gb  # Au lieu de 4gb

# Solution 3: Analyser l'utilisation
redis-cli -h 10.101.X.X3 --scan --pattern "*" | head -100
```

### 10.2 Scripts de Diagnostic

```bash
#!/bin/bash
# Script: health_check_complet.sh
# Diagnostic complet du syst√®me

echo "=== DIAGNOSTIC SAMA CONSO ==="
echo ""

# 1. Serveurs
echo "1. √âtat des serveurs:"
ping -c 1 10.101.X.X1 > /dev/null 2>&1 && echo "  ‚úÖ SERVEUR 1 (DB)" || echo "  ‚ùå SERVEUR 1 (DB)"
ping -c 1 10.101.X.X2 > /dev/null 2>&1 && echo "  ‚úÖ SERVEUR 2 (API)" || echo "  ‚ùå SERVEUR 2 (API)"
ping -c 1 10.101.X.X3 > /dev/null 2>&1 && echo "  ‚úÖ SERVEUR 3 (Workers)" || echo "  ‚ùå SERVEUR 3 (Workers)"
echo ""

# 2. Services
echo "2. √âtat des services:"
curl -sf http://10.101.X.X2:8001/health > /dev/null && echo "  ‚úÖ API Instance 1" || echo "  ‚ùå API Instance 1"
curl -sf http://10.101.X.X2:8002/health > /dev/null && echo "  ‚úÖ API Instance 2" || echo "  ‚ùå API Instance 2"
psql -h 10.101.X.X1 -p 6432 -U samaconso_user -d samaconso -c "SELECT 1;" > /dev/null 2>&1 && echo "  ‚úÖ PostgreSQL" || echo "  ‚ùå PostgreSQL"
redis-cli -h 10.101.X.X3 ping > /dev/null 2>&1 && echo "  ‚úÖ Redis" || echo "  ‚ùå Redis"
curl -sf http://10.101.X.X2:15672 > /dev/null && echo "  ‚úÖ RabbitMQ" || echo "  ‚ùå RabbitMQ"
curl -sf http://10.101.X.X3:5555 --user admin:admin > /dev/null && echo "  ‚úÖ Flower" || echo "  ‚ùå Flower"
echo ""

# 3. Ressources
echo "3. Utilisation des ressources:"
echo "  Espace disque:"
df -h | grep -E "/$|/data" | awk '{print "    " $1 ": " $5 " utilis√©"}'
echo ""

# 4. Conteneurs Docker
echo "4. Conteneurs Docker:"
docker ps --format "  {{.Names}}: {{.Status}}"
echo ""

# 5. Workers Celery
echo "5. Workers Celery:"
WORKERS=$(curl -s http://10.101.X.X3:5555/api/workers --user admin:admin | python3 -c "import sys, json; data=json.load(sys.stdin); print(len(data))")
echo "  Nombre de workers actifs: $WORKERS"
echo ""

# 6. Queues RabbitMQ
echo "6. Files RabbitMQ:"
curl -s -u guest:guest http://10.101.X.X2:15672/api/queues | python3 -c "
import sys, json
data = json.load(sys.stdin)
for queue in data:
    print(f\"  {queue['name']}: {queue['messages']} messages\")
"
echo ""

echo "=== FIN DU DIAGNOSTIC ==="
```

---

## ‚úÖ Checklist de Mise en Production

### Pr√©-D√©ploiement (J-7)

#### Infrastructure
- [ ] 3 serveurs Linux provisionn√©s (Ubuntu 22.04 LTS)
- [ ] Sp√©cifications respect√©es (CPU, RAM, Disque)
- [ ] Acc√®s SSH configur√© avec cl√©s
- [ ] Firewall hardware configur√©
- [ ] Adresses IP assign√©es et document√©es

#### R√©seau
- [ ] Connectivit√© inter-serveurs valid√©e
- [ ] Acc√®s aux serveurs SQL Server valid√©s (SIC, Postpaid)
- [ ] Proxy Senelec configur√© (10.101.201.204:8080)
- [ ] DNS configur√©s (api.samaconso.senelec.sn)
- [ ] Certificats SSL obtenus

#### S√©curit√©
- [ ] Mots de passe forts g√©n√©r√©s
- [ ] Stockage s√©curis√© des secrets (Vault/Ansible)
- [ ] Utilisateurs syst√®me cr√©√©s
- [ ] Sudo configur√©
- [ ] Fail2ban install√© et configur√©

### Installation (J-3 √† J-1)

#### SERVEUR 1 (Base de Donn√©es)
- [ ] PostgreSQL 15 install√©
- [ ] PgBouncer install√© et configur√©
- [ ] MinIO install√© et configur√©
- [ ] Base de donn√©es `samaconso` cr√©√©e
- [ ] Utilisateur `samaconso_user` cr√©√© avec privil√®ges
- [ ] Extensions PostgreSQL install√©es (uuid-ossp, pg_trgm)
- [ ] Backups automatiques configur√©s (cron)
- [ ] Firewall iptables configur√©
- [ ] Monitoring install√© (node_exporter, postgres_exporter)
- [ ] Test de connexion depuis SERVEUR 2 et 3

#### SERVEUR 2 (API)
- [ ] Docker et Docker Compose install√©s
- [ ] Image Docker `samaconso_api:production` disponible
- [ ] Fichier `.env.production` configur√©
- [ ] docker-compose.production.yml d√©ploy√©
- [ ] Certificat Firebase copi√©
- [ ] RabbitMQ d√©marr√© et accessible
- [ ] API Instance 1 d√©marr√©e (port 8001)
- [ ] API Instance 2 d√©marr√©e (port 8002)
- [ ] Health checks fonctionnels
- [ ] Logs configur√©s et rotatifs
- [ ] Firewall iptables configur√©
- [ ] Monitoring install√© (node_exporter)

#### SERVEUR 3 (Workers)
- [ ] Docker et Docker Compose install√©s
- [ ] Image Docker `samaconso_api:production` disponible
- [ ] Fichier `.env.production` configur√©
- [ ] docker-compose.workers.yml d√©ploy√©
- [ ] Redis d√©marr√© et accessible
- [ ] Celery Worker 1 d√©marr√© (queues urgent, high_priority)
- [ ] Celery Worker 2 d√©marr√© (queues normal, low_priority)
- [ ] Flower d√©marr√© et accessible (port 5555)
- [ ] Connexion √† RabbitMQ valid√©e
- [ ] Firewall iptables configur√©
- [ ] Monitoring install√© (node_exporter, redis_exporter)

#### Load Balancer F5
- [ ] Pool `samaconso_api_pool` cr√©√©
- [ ] Members ajout√©s (api_1:8001, api_2:8002)
- [ ] Health monitor configur√© (/health)
- [ ] Virtual Server cr√©√© (VIP: 10.101.X.X0)
- [ ] Load balancing method: Least Connections
- [ ] Session persistence: Cookie Insert
- [ ] SSL/TLS configur√© (si HTTPS)
- [ ] Tests de basculement valid√©s

### Tests (J-2)

#### Tests Fonctionnels
- [ ] Test de login utilisateur
- [ ] Test de consultation consommation
- [ ] Test d'envoi notification push
- [ ] Test d'upload fichier (MinIO)
- [ ] Test de toutes les API principales

#### Tests de Performance
- [ ] Test de charge (1000 requ√™tes simultan√©es)
- [ ] Test de mont√©e en charge progressive
- [ ] Mesure des temps de r√©ponse (< 500ms)
- [ ] V√©rification des ressources (CPU, RAM, Disk)

#### Tests de R√©silience
- [ ] Arr√™t d'une instance API (failover automatique)
- [ ] Arr√™t d'un worker Celery
- [ ] Simulation panne r√©seau
- [ ] Test de rollback

#### Tests de S√©curit√©
- [ ] Scan de vuln√©rabilit√©s (Nessus/OpenVAS)
- [ ] Test d'injection SQL
- [ ] Test XSS
- [ ] V√©rification SSL/TLS
- [ ] Audit des logs

### Go-Live (J-Day)

#### Matin (09h00)
- [ ] Briefing √©quipe technique
- [ ] V√©rification finale tous les services
- [ ] Backup complet base de donn√©es
- [ ] Activation monitoring temps r√©el
- [ ] √âquipe sur site et hotline pr√™te

#### Midi (12h00 - Heure creuse)
- [ ] Basculement DNS/Load Balancer
- [ ] V√©rification premier acc√®s utilisateur
- [ ] Monitoring logs en temps r√©el (15 min)
- [ ] V√©rification m√©triques (CPU, RAM, Network)
- [ ] Test notification push r√©el

#### Apr√®s-midi (14h00-18h00)
- [ ] Tests avec 10 utilisateurs pilotes
- [ ] Validation compl√®te des fonctionnalit√©s
- [ ] Surveillance continue
- [ ] Corrections mineures si n√©cessaire
- [ ] Communication aux utilisateurs (email/SMS)

#### Soir (18h00)
- [ ] Bilan de la journ√©e (r√©union 30 min)
- [ ] Documentation des incidents
- [ ] Planification du lendemain
- [ ] √âquipe d'astreinte d√©sign√©e

### Post-D√©ploiement (J+1 √† J+7)

#### Quotidien
- [ ] Surveillance monitoring (Grafana)
- [ ] Revue logs erreurs
- [ ] V√©rification backups
- [ ] Support utilisateurs
- [ ] Collecte feedback

#### J+7
- [ ] R√©union bilan √©quipe
- [ ] Rapport d√©taill√© (performance, incidents, feedback)
- [ ] Ajustements si n√©cessaire
- [ ] Documentation finale
- [ ] Cl√¥ture projet

---

## üìä M√©triques de Succ√®s

### Objectifs de Performance

| M√©trique | Cible | Critique |
|----------|-------|----------|
| **Disponibilit√©** | 99.9% | 99.5% |
| **Temps de r√©ponse API** | < 500ms | < 1s |
| **Temps de r√©ponse DB** | < 100ms | < 500ms |
| **Notifications envoy√©es** | > 95% | > 90% |
| **Erreurs HTTP** | < 0.1% | < 1% |
| **Connexions simultan√©es** | 10,000 | 5,000 |

### KPIs √† Suivre

**Performance**:
- Temps de r√©ponse moyen par endpoint
- Throughput (requ√™tes/seconde)
- Latence P95, P99

**Fiabilit√©**:
- Uptime (disponibilit√©)
- Taux d'erreur
- Taux de succ√®s notifications

**Ressources**:
- Utilisation CPU (%)
- Utilisation RAM (%)
- Utilisation disque (%)
- Bande passante r√©seau

**Business**:
- Nombre d'utilisateurs actifs
- Nombre de consultations consommation
- Nombre de notifications envoy√©es
- Taux de conversion

---

## üìû Contacts et Support

### √âquipe Projet

| R√¥le | Nom | Contact | Disponibilit√© |
|------|-----|---------|---------------|
| **Chef de Projet** | [Nom] | [Email/T√©l] | 24/7 (astreinte) |
| **Architecte** | [Nom] | [Email/T√©l] | 08h-18h |
| **DevOps** | [Nom] | [Email/T√©l] | 24/7 (astreinte) |
| **DBA** | [Nom] | [Email/T√©l] | 08h-20h |
| **D√©veloppeur Backend** | [Nom] | [Email/T√©l] | 08h-18h |
| **Support N1** | [√âquipe] | [Email/T√©l] | 24/7 |

### Escalade

**Niveau 1** (Incident mineur):
‚Üí Support N1 ‚Üí R√©solution sous 4h

**Niveau 2** (Incident majeur):
‚Üí DevOps/DBA ‚Üí R√©solution sous 2h

**Niveau 3** (Incident critique - Syst√®me down):
‚Üí Chef de Projet + Architecte ‚Üí R√©solution imm√©diate

### Outils de Communication

- **Slack**: #samaconso-prod
- **Email**: ops@senelec.sn
- **T√©l√©phone d'astreinte**: +221 XX XXX XX XX
- **Ticketing**: [Syst√®me de tickets]

---

## üìö Documentation Finale

### Documents √† Maintenir

1. **Architecture** (ce document)
2. **Proc√©dures d'exploitation** (runbook)
3. **Guide de troubleshooting**
4. **Documentation API** (Swagger/OpenAPI)
5. **Sch√©ma base de donn√©es** (ERD)
6. **Configuration r√©seau** (diagrammes)
7. **Proc√©dures de backup/restore**
8. **Changelog** (versions d√©ploy√©es)

### Localisation

```
/opt/samaconso/docs/
‚îú‚îÄ‚îÄ GUIDE_MISE_EN_PRODUCTION.md
‚îú‚îÄ‚îÄ GUIDE_MISE_EN_PRODUCTION_PARTIE2.md
‚îú‚îÄ‚îÄ GUIDE_MISE_EN_PRODUCTION_PARTIE3.md
‚îú‚îÄ‚îÄ ARCHITECTURE.md
‚îú‚îÄ‚îÄ RUNBOOK.md
‚îú‚îÄ‚îÄ TROUBLESHOOTING.md
‚îú‚îÄ‚îÄ CHANGELOG.md
‚îî‚îÄ‚îÄ schemas/
    ‚îú‚îÄ‚îÄ database_erd.png
    ‚îú‚îÄ‚îÄ network_diagram.png
    ‚îî‚îÄ‚îÄ application_flow.png
```

---

## ‚úÖ Conclusion

Ce guide couvre l'ensemble du processus de mise en production de SamaConso API sur une infrastructure haute disponibilit√© √† 3 serveurs.

### Points Cl√©s

‚úÖ **Architecture distribu√©e** avec s√©paration des responsabilit√©s
‚úÖ **Haute disponibilit√©** via Load Balancer F5 et instances multiples
‚úÖ **Scalabilit√©** horizontale et verticale possible
‚úÖ **S√©curit√©** renforc√©e (firewall, SSL, secrets management)
‚úÖ **Monitoring** complet (Prometheus, Grafana, Alerting)
‚úÖ **Backup** automatique et proc√©dures de rollback
‚úÖ **Documentation** exhaustive et maintenable

### Capacit√©

**1 Million d'utilisateurs support√©s** gr√¢ce √†:
- PgBouncer (10,000 connexions clients)
- Redis (cache haute performance)
- Load Balancer F5 (distribution de charge)
- Workers Celery multiples (traitement asynchrone)
- Architecture scalable (ajout d'instances possible)

### Prochaines √âtapes

1. **Validation par l'√©quipe technique**
2. **Revue par l'√©quipe s√©curit√©**
3. **Approbation management**
4. **Planification d√©ploiement** (dates, ressources)
5. **Formation √©quipe exploitation**
6. **Go-Live**

---

**Version**: 1.0
**Date**: 2025-11-12
**Auteurs**: √âquipe SamaConso
**Statut**: ‚úÖ Pr√™t pour production

üöÄ **Bonne mise en production!**
