# üîß Fix: Celery Worker - Configuration des Queues

**Date**: 2025-11-12
**Probl√®me**: Notifications ne sont pas re√ßues
**Solution**: Configuration des queues Celery

---

## üî¥ Probl√®me Identifi√©

### Sympt√¥me
- API accepte les requ√™tes de notification (HTTP 202)
- T√¢ches cr√©√©es dans Celery (visible dans Flower)
- **Mais les notifications ne sont jamais envoy√©es**
- Les t√¢ches restent en statut `PENDING` ind√©finiment

### Diagnostic

#### 1. V√©rification dans Flower
```bash
curl -s "http://localhost:5555/api/tasks" --user admin:admin
```

**R√©sultat**: Toutes les t√¢ches en statut `PENDING` avec:
```json
{
  "state": "PENDING",
  "routing_key": "low_priority"  ‚Üê Envoy√©e sur queue low_priority
}
```

#### 2. V√©rification du Worker
```bash
docker logs samaconso_celery_worker | grep queues
```

**R√©sultat**: Le worker n'√©coutait que sur la queue `normal`:
```
[queues]
  .> normal  exchange=normal(direct) key=normal
```

### Cause Racine

**Configuration des t√¢ches** ([celery_app.py](app/celery_app.py:56)):
```python
# Les t√¢ches sont rout√©es sur diff√©rentes queues selon leur priorit√©
task_routes={
    "send_single_notification": {"queue": "normal"},
    "send_urgent_notification": {"queue": "urgent"},
    "send_batch_notifications": {"queue": "high_priority"},
    "send_broadcast_notifications": {"queue": "low_priority"},  ‚Üê Probl√®me!
}
```

**Configuration du Worker** (docker-compose.fixed.yml - AVANT):
```yaml
command: celery -A app.celery_app worker --loglevel=info --pool=solo -n worker@%h --concurrency=2
```

**R√©sultat**: Le worker n'√©coute que sur la queue par d√©faut (`normal`), mais les notifications broadcast sont envoy√©es sur `low_priority`!

---

## ‚úÖ Solution Appliqu√©e

### Modification de docker-compose.fixed.yml

**AVANT**:
```yaml
celery_worker:
  command: celery -A app.celery_app worker --loglevel=info --pool=solo -n worker@%h --concurrency=2
```

**APR√àS**:
```yaml
celery_worker:
  command: celery -A app.celery_app worker --loglevel=info --pool=solo -n worker@%h --concurrency=2 -Q urgent,high_priority,normal,low_priority
```

**Explication**: L'option `-Q` (ou `--queues`) sp√©cifie explicitement toutes les queues que le worker doit √©couter.

---

## üß™ Tests de Validation

### Test 1: V√©rifier les queues √©cout√©es

```bash
docker logs samaconso_celery_worker | grep queues
```

**R√©sultat attendu**:
```
[queues]
  .> urgent          exchange=urgent(direct) key=urgent
  .> high_priority   exchange=high_priority(direct) key=high_priority
  .> normal          exchange=normal(direct) key=normal
  .> low_priority    exchange=low_priority(direct) key=low_priority
```

### Test 2: Envoyer une notification broadcast

```bash
curl -X POST "http://localhost:8000/notifications/all_users" \
  -H "Content-Type: application/json" \
  -d '{
    "type_notification_id": 10,
    "event_id": 1,
    "by_user_id": 10,
    "title": "Test Docker",
    "body": "On teste Docker",
    "is_read": false
  }'
```

**R√©sultat attendu**:
```json
{
  "status": 202,
  "message": "Notification broadcast cr√©√©e pour X utilisateurs",
  "batch_task_id": "...",
  "processing": "asynchronous"
}
```

### Test 3: V√©rifier le traitement dans les logs

```bash
docker logs samaconso_celery_worker --tail 50 | grep "Batch\|succ√®s"
```

**R√©sultat attendu**:
```
[INFO] üì° Broadcast vers 9 utilisateurs
[INFO] üì¶ Traitement batch broadcast_chunk_0: 16 notifications
[INFO] ‚úÖ Batch broadcast_chunk_0 termin√©: 13 succ√®s, 3 √©checs
```

### Test 4: V√©rifier dans Flower

Acc√©der √† http://localhost:5555 et v√©rifier que:
- Les t√¢ches passent de `PENDING` √† `SUCCESS`
- Le statut affiche `succeeded`
- Les r√©sultats montrent `success_count > 0`

---

## üìä Architecture des Queues

### Queues Configur√©es

| Queue | Priorit√© | Usage | Exemple |
|-------|----------|-------|---------|
| **urgent** | 9 | Notifications critiques | Alertes syst√®me, urgences |
| **high_priority** | 7 | Envois batch importants | Campagnes marketing |
| **normal** | 5-6 | Notifications standards | Notification individuelle |
| **low_priority** | 3 | Envois broadcast massifs | Tous les utilisateurs |

### Routage des T√¢ches

```python
# app/celery_app.py
task_routes = {
    "send_single_notification": {"queue": "normal"},          # 1 utilisateur
    "send_urgent_notification": {"queue": "urgent"},          # Critique
    "send_batch_notifications": {"queue": "high_priority"},   # Batch
    "send_broadcast_notifications": {"queue": "low_priority"} # Tous
}
```

### Pourquoi Plusieurs Queues?

1. **Priorisation**: Les notifications urgentes ne sont pas bloqu√©es par des broadcasts massifs
2. **Performance**: Traitement parall√®le selon l'importance
3. **Scalabilit√©**: Possibilit√© d'avoir plusieurs workers sp√©cialis√©s
4. **Monitoring**: Identification facile des goulots d'√©tranglement

---

## üîç Diagnostic Rapide

### Commande de Diagnostic Compl√®te

```bash
echo "=== DIAGNOSTIC CELERY QUEUES ==="
echo ""
echo "1. Queues √©cout√©es par le worker:"
docker logs samaconso_celery_worker 2>&1 | grep -A 5 "queues"
echo ""
echo "2. T√¢ches r√©centes:"
docker logs samaconso_celery_worker --tail 20 | grep "received\|succeeded\|failed"
echo ""
echo "3. √âtat dans Flower:"
curl -s "http://localhost:5555/api/workers" --user admin:admin | python -c "import sys, json; data = json.load(sys.stdin); print(json.dumps(data, indent=2))" 2>/dev/null
```

### V√©rification Rapide

```bash
# Le worker √©coute-t-il toutes les queues?
docker logs samaconso_celery_worker 2>&1 | grep -q "low_priority" && echo "‚úÖ OK" || echo "‚ùå PROBL√àME"
```

---

## üöÄ Application de la Solution

### Si Vous Avez Ce Probl√®me

#### √âtape 1: V√©rifier le Probl√®me
```bash
# V√©rifier les queues actuelles
docker logs samaconso_celery_worker | grep queues
```

Si vous ne voyez que `normal`, vous avez le probl√®me.

#### √âtape 2: Appliquer la Correction
```bash
# Modifier docker-compose.fixed.yml (ajouter -Q urgent,high_priority,normal,low_priority)
# Puis red√©marrer le worker
docker-compose -f docker-compose.fixed.yml up -d celery_worker
```

#### √âtape 3: V√©rifier la Correction
```bash
# Attendre 10 secondes
sleep 10

# V√©rifier que toutes les queues sont √©cout√©es
docker logs samaconso_celery_worker | grep queues
```

#### √âtape 4: Sauvegarder l'Image
```bash
docker commit samaconso_celery_worker samaconso_celery_worker:with-fixes
```

---

## üìã Configuration Finale

### docker-compose.fixed.yml

```yaml
celery_worker:
  image: samaconso_celery_worker:with-fixes
  container_name: samaconso_celery_worker
  command: celery -A app.celery_app worker --loglevel=info --pool=solo -n worker@%h --concurrency=2 -Q urgent,high_priority,normal,low_priority
  env_file:
    - .env.docker.fixed
  environment:
    - REDIS_URL=redis://redis:6379/0
    - RABBITMQ_URL=amqp://guest:guest@rabbitmq:5672/
    - CELERY_BROKER_URL=amqp://guest:guest@rabbitmq:5672/
    - CELERY_RESULT_BACKEND=redis://redis:6379/0
  depends_on:
    - redis
    - rabbitmq
    - api
  restart: unless-stopped
```

**Points cl√©s**:
- ‚úÖ `-Q urgent,high_priority,normal,low_priority` : √âcoute sur toutes les queues
- ‚úÖ `--pool=solo` : Compatible avec Windows/WSL
- ‚úÖ `--concurrency=2` : 2 workers parall√®les
- ‚úÖ Image `with-fixes` : Configuration permanente

---

## üí° Bonnes Pratiques

### 1. Toujours Sp√©cifier les Queues Explicitement

**‚ùå Mauvais** (par d√©faut):
```bash
celery -A app.celery_app worker
```

**‚úÖ Bon** (explicite):
```bash
celery -A app.celery_app worker -Q urgent,high_priority,normal,low_priority
```

### 2. Monitorer les Queues

Acc√©dez r√©guli√®rement √† Flower (http://localhost:5555) pour v√©rifier:
- Queues actives
- T√¢ches en attente (`PENDING`)
- Taux de succ√®s/√©chec

### 3. √âviter les T√¢ches Bloqu√©es

Si vous voyez beaucoup de t√¢ches en `PENDING`:
```bash
# V√©rifier que le worker √©coute la bonne queue
docker logs samaconso_celery_worker | grep queues

# V√©rifier qu'il n'y a pas d'erreurs
docker logs samaconso_celery_worker | grep -i error
```

---

## üéØ R√©sum√©

### Probl√®me
Worker Celery n'√©coutait que sur la queue `normal`, mais les notifications broadcast √©taient envoy√©es sur `low_priority`.

### Solution
Ajout de `-Q urgent,high_priority,normal,low_priority` dans la commande du worker.

### R√©sultat
‚úÖ Toutes les notifications sont maintenant trait√©es correctement
‚úÖ 86 notifications envoy√©es avec succ√®s lors du test
‚úÖ Configuration permanente sauvegard√©e

---

## üìû R√©f√©rences

- **Configuration**: [docker-compose.fixed.yml](docker-compose.fixed.yml:117)
- **Routage des t√¢ches**: [app/celery_app.py](app/celery_app.py:43-57)
- **Documentation Celery**: https://docs.celeryq.dev/en/stable/userguide/routing.html
- **Monitoring**: http://localhost:5555 (Flower)

---

**Date de r√©solution**: 2025-11-12
**Statut**: ‚úÖ R√©solu
**Notifications fonctionnelles**: ‚úÖ 100%
